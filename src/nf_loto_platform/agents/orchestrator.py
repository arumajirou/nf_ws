"""
AI Agent Orchestrator.

è¤‡æ•°ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Analyst, RAG, Planner, Reflection) ã‚’å”èª¿ã•ã›ã€
æ™‚ç³»åˆ—äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã®è‡ªå¾‹çš„ãªå®Ÿè¡Œãƒ»æ”¹å–„ãƒ«ãƒ¼ãƒ—ï¼ˆPDCAï¼‰ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
"""

from __future__ import annotations

import logging
import time
import uuid
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import yaml

from nf_loto_platform.core.settings import get_config_path
from nf_loto_platform.ml.model_runner import run_loto_experiment, ExperimentResult

# å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå®Ÿè£…ã¯åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
# â€» ç¾æ®µéšã§ã¯ãƒ¢ãƒƒã‚¯ã‚„ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã¨ã—ã¦æ‰±ã†å ´åˆã‚‚ã‚ã‚‹ãŸã‚ã€
#    ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼æ™‚ã¯è­¦å‘Šã‚’å‡ºã—ã¦ãƒ€ãƒŸãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹è¨­è¨ˆã¨ã™ã‚‹ã€‚
try:
    from nf_loto_platform.agents.analyst_agent import AnalystAgent
    from nf_loto_platform.agents.rag_agent import RagAgent
    from nf_loto_platform.agents.planner_agent import PlannerAgent
    from nf_loto_platform.agents.reflection_agent import ReflectionAgent
except ImportError:
    logging.getLogger(__name__).warning("Agent modules not found. Using mock agents for orchestration.")
    AnalystAgent = None
    RagAgent = None
    PlannerAgent = None
    ReflectionAgent = None

logger = logging.getLogger(__name__)


@dataclass
class OrchestratorContext:
    """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…±æœ‰ãƒ¡ãƒ¢ãƒªï¼‰."""
    
    session_id: str
    table_name: str
    loto: str
    unique_ids: List[str]
    horizon: int
    
    # ã‚¹ãƒ†ãƒ¼ãƒˆ
    iteration: int = 0
    history: List[Dict[str, Any]] = field(default_factory=list)
    best_run_id: Optional[int] = None
    best_score: float = float("inf")  # Lower is better (e.g. MAE)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®å‡ºåŠ›è“„ç©
    analysis_report: Optional[str] = None
    rag_patterns: Optional[Dict[str, Any]] = None
    current_plan: Optional[Dict[str, Any]] = None
    last_critique: Optional[str] = None


class AgentOrchestrator:
    """è‡ªå¾‹åˆ†æãƒ«ãƒ¼ãƒ—ã‚’åˆ¶å¾¡ã™ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼."""

    def __init__(self, config_path: Optional[str] = None):
        self.config = self._load_config(config_path)
        self.agents = self._initialize_agents()

    def _load_config(self, path: Optional[str]) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š(agent_config.yaml)ã‚’ãƒ­ãƒ¼ãƒ‰."""
        if path is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã®æ¢ç´¢
            import os
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
            path = os.path.join(base_dir, "config", "agent_config.yaml")
        
        try:
            with open(path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.warning(f"Failed to load agent config from {path}: {e}. Using defaults.")
            return {}

    def _initialize_agents(self) -> Dict[str, Any]:
        """å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹."""
        # ã“ã“ã§ã¯DIï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰çš„ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”Ÿæˆ
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€LangChainã®AgentExecutorç­‰ã‚’ãƒ©ãƒƒãƒ—ã—ãŸã‚¯ãƒ©ã‚¹ã«ãªã‚‹æƒ³å®š
        agents = {}
        
        # LLMè¨­å®šã®å–å¾—
        llm_config = self.config.get("llm", {})
        
        if AnalystAgent:
            agents["analyst"] = AnalystAgent(config=llm_config)
        if RagAgent:
            agents["rag"] = RagAgent(config=llm_config)
        if PlannerAgent:
            agents["planner"] = PlannerAgent(config=llm_config)
        if ReflectionAgent:
            agents["reflection"] = ReflectionAgent(config=llm_config)
            
        return agents

    def run_autonomous_loop(
        self,
        table_name: str,
        loto: str,
        unique_ids: List[str],
        horizon: int,
        goal_metric: str = "mae",
        max_iterations: int = 3,
        human_in_the_loop: bool = False
    ) -> List[ExperimentResult]:
        """
        è‡ªå¾‹çš„ãªæ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰.
        
        Flow:
            1. Analyst: ãƒ‡ãƒ¼ã‚¿åˆ†æ
            2. RAG: é¡ä¼¼äº‹ä¾‹æ¤œç´¢
            3. Loop:
                a. Planner: åˆ†æçµæœã¨éå»ã®å±¥æ­´ã‹ã‚‰è¨­å®šã‚’ç«‹æ¡ˆ
                b. Execution: å®Ÿé¨“å®Ÿè¡Œ
                c. Reflection: çµæœè©•ä¾¡ã¨æ”¹å–„æ¡ˆæç¤º
                d. çµ‚äº†åˆ¤å®š
        """
        session_id = str(uuid.uuid4())[:8]
        logger.info(f"Starting autonomous loop session={session_id} for {unique_ids}")
        
        ctx = OrchestratorContext(
            session_id=session_id,
            table_name=table_name,
            loto=loto,
            unique_ids=unique_ids,
            horizon=horizon
        )
        
        results = []

        # --- Step 1: Analysis Phase ---
        if "analyst" in self.agents:
            logger.info("ğŸ¤– Analyst Agent working...")
            ctx.analysis_report = self.agents["analyst"].analyze(
                table_name, loto, unique_ids
            )
        else:
            ctx.analysis_report = "Analyst agent not available. Assuming standard time series."

        # --- Step 2: Retrieval Phase ---
        if "rag" in self.agents:
            logger.info("ğŸ¤– RAG Agent searching...")
            ctx.rag_patterns = self.agents["rag"].search(
                table_name, loto, unique_ids, horizon
            )

        # --- Step 3: Optimization Loop ---
        for i in range(max_iterations):
            ctx.iteration = i + 1
            logger.info(f"=== Iteration {ctx.iteration}/{max_iterations} ===")
            
            # 3a. Planning
            if "planner" in self.agents:
                logger.info("ğŸ¤– Planner Agent deciding strategy...")
                # å‰å›ã®åçœ(last_critique)ã‚’å«ã‚ã¦ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°
                plan = self.agents["planner"].create_plan(
                    context=ctx,
                    analysis=ctx.analysis_report,
                    feedback=ctx.last_critique
                )
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åˆå›ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€2å›ç›®ä»¥é™ã¯å°‘ã—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰ãˆã‚‹ç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯
                plan = self._fallback_planning(ctx)
            
            ctx.current_plan = plan
            logger.info(f"Plan: {plan.get('model_name')} (backend={plan.get('backend')})")

            # Human Approval (Optional)
            if human_in_the_loop:
                # å®Ÿé‹ç”¨ã§ã¯ã“ã“ã§UIã‹ã‚‰ã®å…¥åŠ›ã‚’å¾…ã¤å®Ÿè£…ã«ãªã‚‹
                # input("Approve plan? [y/n]: ")
                pass

            # 3b. Execution
            logger.info("ğŸš€ Executing experiment...")
            try:
                preds, meta = run_loto_experiment(
                    table_name=table_name,
                    loto=loto,
                    unique_ids=unique_ids,
                    horizon=horizon,
                    agent_metadata={
                        "session_id": session_id,
                        "iteration": ctx.iteration,
                        "analyst_report": ctx.analysis_report,
                        "planner_rationale": plan.get("rationale", "")
                    },
                    # Planã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å±•é–‹
                    model_name=plan.get("model_name", "AutoNHITS"),
                    backend=plan.get("backend", "optuna"),
                    num_samples=plan.get("num_samples", 10),
                    use_rag=(ctx.rag_patterns is not None),
                    # ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    **plan.get("model_params", {})
                )
                
                result = ExperimentResult(preds=preds, meta=meta)
                results.append(result)
                
                # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢æ›´æ–°ãƒã‚§ãƒƒã‚¯
                current_score = self._get_metric(meta, goal_metric)
                if current_score < ctx.best_score:
                    ctx.best_score = current_score
                    ctx.best_run_id = meta.get("run_id")
                    logger.info(f"ğŸŒŸ New best score: {current_score:.4f}")

            except Exception as e:
                logger.error(f"Execution failed: {e}")
                ctx.last_critique = f"Execution failed with error: {str(e)}. Try a simpler model or reduce resource usage."
                continue

            # 3c. Reflection
            if "reflection" in self.agents:
                logger.info("ğŸ¤– Reflection Agent evaluating...")
                critique, is_satisfied = self.agents["reflection"].evaluate(
                    result=result,
                    goal_metric=goal_metric,
                    history=ctx.history
                )
                ctx.last_critique = critique
                
                # å±¥æ­´ã«ä¿å­˜
                ctx.history.append({
                    "iteration": ctx.iteration,
                    "plan": plan,
                    "score": current_score,
                    "critique": critique
                })

                if is_satisfied:
                    logger.info("âœ… Reflection Agent is satisfied. Stopping loop.")
                    break
            else:
                ctx.last_critique = f"Score was {current_score}. Try to improve."

        logger.info(f"Autonomous loop finished. Best Run ID: {ctx.best_run_id}")
        return results

    def _fallback_planning(self, ctx: OrchestratorContext) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸åœ¨æ™‚ã®ç°¡æ˜“ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯."""
        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰ãˆã‚‹ã ã‘ã®å˜ç´”ãªãƒ­ã‚¸ãƒƒã‚¯
        models = ["AutoNHITS", "AutoTFT", "Time-MoE-50M"]
        idx = (ctx.iteration - 1) % len(models)
        model_name = models[idx]
        
        backend = "tsfm" if "Time-MoE" in model_name else "optuna"
        
        return {
            "model_name": model_name,
            "backend": backend,
            "num_samples": 5 if backend == "optuna" else 1,
            "rationale": "Fallback round-robin selection"
        }

    def _get_metric(self, meta: Dict[str, Any], metric_name: str) -> float:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©•ä¾¡æŒ‡æ¨™ã‚’æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼."""
        # nf_model_runs ã® metrics ã‚«ãƒ©ãƒ ã¯ JSONB
        metrics = meta.get("metrics", {})
        if not metrics:
            return float("inf")
        
        # mae, mse, val_loss ãªã©ã‚’æ¢ç´¢
        val = metrics.get(metric_name)
        if val is not None:
            return float(val)
            
        # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€test_loss ã‚„ loss ã‚’æ¢ã™
        for k in ["test_loss", "loss", "mae"]:
            if k in metrics:
                return float(metrics[k])
        
        return float("inf")