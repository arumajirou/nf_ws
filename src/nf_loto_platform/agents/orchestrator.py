"""
AI Agent Orchestrator.

è¤‡æ•°ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Analyst, RAG, Planner, Reflection) ã‚’å”èª¿ã•ã›ã€
æ™‚ç³»åˆ—äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã®è‡ªå¾‹çš„ãªå®Ÿè¡Œãƒ»æ”¹å–„ãƒ«ãƒ¼ãƒ—ï¼ˆPDCAï¼‰ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
"""

from __future__ import annotations

import logging
import time
import uuid
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import yaml

# å®Ÿè£…ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from nf_loto_platform.agents.analyst_agent import AnalystAgent
from nf_loto_platform.agents.rag_agent import RagAgent
from nf_loto_platform.agents.planner_agent import PlannerAgent
from nf_loto_platform.agents.reflection_agent import ReflectionAgent
from nf_loto_platform.agents.domain import TimeSeriesTaskSpec, CuratorOutput

from nf_loto_platform.ml.model_runner import run_loto_experiment, ExperimentResult

logger = logging.getLogger(__name__)


@dataclass
class OrchestratorContext:
    """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…±æœ‰ãƒ¡ãƒ¢ãƒªï¼‰."""
    
    session_id: str
    table_name: str
    loto: str
    unique_ids: List[str]
    horizon: int
    
    # ã‚¹ãƒ†ãƒ¼ãƒˆ
    iteration: int = 0
    history: List[Dict[str, Any]] = field(default_factory=list)
    best_run_id: Optional[int] = None
    best_score: float = float("inf")  # Lower is better (e.g. MAE)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®å‡ºåŠ›è“„ç©
    analysis_report: Optional[str] = None
    rag_patterns: Optional[Dict[str, Any]] = None
    current_plan: Optional[Any] = None # ExperimentRecipe
    last_critique: Optional[str] = None


class AgentOrchestrator:
    """è‡ªå¾‹åˆ†æãƒ«ãƒ¼ãƒ—ã‚’åˆ¶å¾¡ã™ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼."""

    def __init__(self, config_path: Optional[str] = None):
        self.config = self._load_config(config_path)
        self.agents = self._initialize_agents()

    def _load_config(self, path: Optional[str]) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰."""
        if path is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ç­‰ã¯çœç•¥ã€ç©ºã®å ´åˆã¯ç©ºè¾æ›¸ã§ç¶šè¡Œ
            return {}
        try:
            with open(path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.warning(f"Failed to load agent config: {e}")
            return {}

    def _initialize_agents(self) -> Dict[str, Any]:
        """å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹."""
        agents = {}
        
        # å…¨ä½“ã®è¨­å®šã‚’æ¸¡ã™ (å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå†…ã§å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—ã•ã›ã‚‹)
        try:
            agents["analyst"] = AnalystAgent(config=self.config)
            agents["rag"] = RagAgent(config=self.config)
            agents["planner"] = PlannerAgent() # Plannerã¯Registryä¾å­˜(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨)
            agents["reflection"] = ReflectionAgent(config=self.config)
            logger.info("All agents initialized successfully.")
        except Exception as e:
            logger.error(f"Failed to initialize agents: {e}")
            # å¿…è¦ã«å¿œã˜ã¦raiseã™ã‚‹ã‹ã€ä¸€éƒ¨ã®ã¿ã§ç¶šè¡Œã™ã‚‹
            
        return agents

    def run_autonomous_loop(
        self,
        table_name: str,
        loto: str,
        unique_ids: List[str],
        horizon: int,
        goal_metric: str = "mae",
        max_iterations: int = 3,
        human_in_the_loop: bool = False
    ) -> List[ExperimentResult]:
        """
        è‡ªå¾‹çš„ãªæ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰.
        """
        session_id = str(uuid.uuid4())[:8]
        logger.info(f"Starting autonomous loop session={session_id} for {unique_ids}")
        
        ctx = OrchestratorContext(
            session_id=session_id,
            table_name=table_name,
            loto=loto,
            unique_ids=unique_ids,
            horizon=horizon
        )
        
        results = []

        # --- Step 1: Analysis Phase ---
        if "analyst" in self.agents:
            logger.info("ğŸ¤– Analyst Agent working...")
            try:
                ctx.analysis_report = self.agents["analyst"].analyze(
                    table_name, loto, unique_ids
                )
            except Exception as e:
                logger.error(f"Analyst agent failed: {e}")
                ctx.analysis_report = "Analysis failed."

        # --- Step 2: Retrieval Phase ---
        if "rag" in self.agents:
            logger.info("ğŸ¤– RAG Agent searching...")
            try:
                ctx.rag_patterns = self.agents["rag"].search(
                    table_name, loto, unique_ids, horizon
                )
            except Exception as e:
                logger.error(f"RAG agent failed: {e}")
                ctx.rag_patterns = None

        # --- Step 3: Optimization Loop ---
        for i in range(max_iterations):
            ctx.iteration = i + 1
            logger.info(f"=== Iteration {ctx.iteration}/{max_iterations} ===")
            
            # 3a. Planning
            plan = None
            if "planner" in self.agents:
                logger.info("ğŸ¤– Planner Agent deciding strategy...")
                
                # Plannerç”¨ã®å…¥åŠ›ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹ç¯‰
                # ç°¡æ˜“çš„ãªCuratorOutputã®ä½œæˆ (æœ¬æ¥ã¯CuratorAgentãŒè¡Œã†)
                curator_out = CuratorOutput(
                    dataset_properties={"n_obs": 2000} # ä»®ã®å€¤
                )
                
                task_spec = TimeSeriesTaskSpec(
                    target_horizon=horizon,
                    max_training_time_minutes=30
                )
                
                try:
                    plan = self.agents["planner"].plan(task_spec, curator_out)
                except Exception as e:
                    logger.error(f"Planner failed: {e}")

            if not plan:
                plan = self._fallback_planning(ctx)
            
            ctx.current_plan = plan
            
            # Plan (ExperimentRecipe) ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            model_name = plan.get("model_name") if hasattr(plan, "get") else plan.models[0]
            backend = plan.get("backend") if hasattr(plan, "get") else plan.search_backend
            
            logger.info(f"Plan: {model_name} (backend={backend})")

            # 3b. Execution
            logger.info("ğŸš€ Executing experiment...")
            try:
                # Recipeã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å±•é–‹
                params = plan.get("model_params", {}) if hasattr(plan, "get") else plan.extra_params
                
                preds, meta = run_loto_experiment(
                    table_name=table_name,
                    loto=loto,
                    unique_ids=unique_ids,
                    horizon=horizon,
                    agent_metadata={
                        "session_id": session_id,
                        "iteration": ctx.iteration,
                        "analyst_report": ctx.analysis_report,
                    },
                    model_name=model_name,
                    backend=backend,
                    # use_rag=True if ctx.rag_patterns else False,
                    **params
                )
                
                result = ExperimentResult(preds=preds, meta=meta)
                results.append(result)
                
                current_score = self._get_metric(meta, goal_metric)
                if current_score < ctx.best_score:
                    ctx.best_score = current_score
                    ctx.best_run_id = meta.get("run_id")
                    logger.info(f"ğŸŒŸ New best score: {current_score:.4f}")

            except Exception as e:
                logger.error(f"Execution failed: {e}")
                ctx.last_critique = f"Execution error: {str(e)}"
                continue

            # 3c. Reflection
            if "reflection" in self.agents:
                logger.info("ğŸ¤– Reflection Agent evaluating...")
                try:
                    critique, is_satisfied = self.agents["reflection"].evaluate(
                        result=result,
                        goal_metric=goal_metric,
                        history=ctx.history
                    )
                    ctx.last_critique = critique
                    
                    ctx.history.append({
                        "iteration": ctx.iteration,
                        "score": current_score,
                        "critique": critique
                    })

                    if is_satisfied:
                        logger.info("âœ… Reflection Agent is satisfied. Stopping loop.")
                        break
                except Exception as e:
                    logger.error(f"Reflection failed: {e}")

        logger.info(f"Autonomous loop finished. Best Run ID: {ctx.best_run_id}")
        return results

    def _fallback_planning(self, ctx: OrchestratorContext) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡æ˜“ãƒ—ãƒ©ãƒ³."""
        return {
            "model_name": "AutoNHITS",
            "backend": "optuna",
            "num_samples": 5,
            "model_params": {}
        }

    def _get_metric(self, meta: Dict[str, Any], metric_name: str) -> float:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©•ä¾¡æŒ‡æ¨™ã‚’æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼."""
        metrics = meta.get("metrics", {})
        if not metrics:
            return float("inf")
        return float(metrics.get(metric_name, metrics.get("mae", float("inf"))))