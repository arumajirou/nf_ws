"""
AI Agent Orchestrator.

è¤‡æ•°ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Analyst, RAG, Planner, Reflection) ã‚’å”èª¿ã•ã›ã€
æ™‚ç³»åˆ—äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã®è‡ªå¾‹çš„ãªå®Ÿè¡Œãƒ»æ”¹å–„ãƒ«ãƒ¼ãƒ—ï¼ˆPDCAï¼‰ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
"""

from __future__ import annotations

import logging
import time
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union


import pandas as pd
import yaml

from nf_loto_platform.core.settings import get_config_path
from nf_loto_platform.ml.model_runner import run_loto_experiment, ExperimentResult
from nf_loto_platform.agents.domain import (
    AgentReport,
    ExperimentOutcome,
    TimeSeriesTaskSpec,
    ExperimentRecipe
)

# å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from nf_loto_platform.agents.analyst_agent import AnalystAgent
    from nf_loto_platform.agents.rag_agent import RagAgent
    from nf_loto_platform.agents.planner_agent import PlannerAgent
    from nf_loto_platform.agents.reflection_agent import ReflectionAgent
except ImportError:
    logging.getLogger(__name__).warning("Agent modules not found. Using mock agents for orchestration.")
    AnalystAgent = None
    RagAgent = None
    PlannerAgent = None
    ReflectionAgent = None

try:
    from nf_loto_platform.agents.ts_research_orchestrator import TSResearchOrchestrator
except ImportError:
    TSResearchOrchestrator = None


logger = logging.getLogger(__name__)


@dataclass
class OrchestratorContext:
    """ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…±æœ‰ãƒ¡ãƒ¢ãƒªï¼‰."""
    
    session_id: str
    table_name: str
    loto: str
    unique_ids: List[str]
    horizon: int
    
    # ã‚¹ãƒ†ãƒ¼ãƒˆ
    iteration: int = 0
    history: List[Dict[str, Any]] = field(default_factory=list)
    best_run_id: Optional[int] = None
    best_score: float = float("inf")  # Lower is better (e.g. MAE)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®å‡ºåŠ›è“„ç©
    analysis_report: Optional[str] = None
    rag_patterns: Optional[Dict[str, Any]] = None
    current_plan: Optional[Dict[str, Any]] = None
    last_critique: Optional[str] = None


class AgentOrchestrator:
    """è‡ªå¾‹åˆ†æãƒ«ãƒ¼ãƒ—ã‚’åˆ¶å¾¡ã™ã‚‹ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼."""

    def __init__(
        self, 
        config_path: Optional[str] = None,
        llm_client: Any = None,
        # äº’æ›æ€§ã®ãŸã‚ã«å¼•æ•°ã‚’å—ã‘å…¥ã‚Œã‚‹ãŒã€å†…éƒ¨ã§ã¯é©åˆ‡ã«å‡¦ç†ã™ã‚‹
        curator: Any = None,
        planner: Any = None,
        forecaster: Any = None,
        reporter: Any = None,
    ):
        self.config = self._load_config(config_path)
        self.llm_client = llm_client
        
        # å¤–éƒ¨ã‹ã‚‰æ³¨å…¥ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†ï¼ˆãƒ†ã‚¹ãƒˆã‚„EasyTSFç”¨ï¼‰
        # ãªã‘ã‚Œã°å†…éƒ¨ã§åˆæœŸåŒ–ã™ã‚‹
        self.agents = {}
        if curator or planner or forecaster or reporter:
             # EasyTSFã‹ã‚‰ã®æ³¨å…¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®ç°¡æ˜“å¯¾å¿œ
             # â€» æœ¬æ¥ã¯å½¹å‰²ï¼ˆAnalyst vs Curatorï¼‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå¿…è¦ã ãŒã€ä¸€æ—¦ä¿æŒã—ã¦ãŠã
             self.agents["analyst"] = curator
             self.agents["planner"] = planner
             self.agents["forecaster"] = forecaster # ForecasterAgent (runner wrapper)
             self.agents["reflection"] = reporter
        else:
            self.agents = self._initialize_agents()

    def _load_config(self, path: Optional[str]) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š(agent_config.yaml)ã‚’ãƒ­ãƒ¼ãƒ‰."""
        if path is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã®æ¢ç´¢
            try:
                from nf_loto_platform.core.settings import load_agent_config
                return load_agent_config()
            except ImportError:
                return {}
        
        try:
            with open(path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.warning(f"Failed to load agent config from {path}: {e}. Using defaults.")
            return {}

    def _initialize_agents(self) -> Dict[str, Any]:
        """å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹."""
        agents = {}
        
        # LLMè¨­å®šã®å–å¾—
        llm_config = self.config.get("llm", {})
        
        # ã‚‚ã—LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒæ³¨å…¥ã•ã‚Œã¦ã„ã‚Œã°ã€ãã‚Œã‚’å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¸¡ã™è¨­è¨ˆã«ã™ã¹ãã ãŒã€
        # æ—¢å­˜ã®Agentå®Ÿè£…ã¯ config è¾æ›¸ã‚’å—ã‘å–ã‚‹å½¢ã«ãªã£ã¦ã„ã‚‹å ´åˆãŒå¤šã„ã€‚
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«åˆæœŸåŒ–ã™ã‚‹ã€‚

        if AnalystAgent:
            agents["analyst"] = AnalystAgent(config=llm_config)
        if RagAgent:
            agents["rag"] = RagAgent(config=llm_config)
        if PlannerAgent:
            agents["planner"] = PlannerAgent(config=llm_config)
        if ReflectionAgent:
            agents["reflection"] = ReflectionAgent(config=llm_config)
            
        return agents

    def run_autonomous_loop(
        self,
        table_name: str,
        loto: str,
        unique_ids: List[str],
        horizon: int,
        goal_metric: str = "mae",
        max_iterations: int = 3,
        human_in_the_loop: bool = False
    ) -> List[ExperimentResult]:
        """
        è‡ªå¾‹çš„ãªæ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰.
        """
        session_id = str(uuid.uuid4())[:8]
        logger.info(f"Starting autonomous loop session={session_id} for {unique_ids}")
        
        ctx = OrchestratorContext(
            session_id=session_id,
            table_name=table_name,
            loto=loto,
            unique_ids=unique_ids,
            horizon=horizon
        )
        
        results = []

        # --- Step 1: Analysis Phase ---
        if "analyst" in self.agents and hasattr(self.agents["analyst"], "analyze"):
            logger.info("ğŸ¤– Analyst Agent working...")
            ctx.analysis_report = self.agents["analyst"].analyze(
                table_name, loto, unique_ids
            )
        else:
            ctx.analysis_report = "Analyst agent not available. Assuming standard time series."

        # --- Step 2: Retrieval Phase ---
        if "rag" in self.agents:
            logger.info("ğŸ¤– RAG Agent searching...")
            ctx.rag_patterns = self.agents["rag"].search(
                table_name, loto, unique_ids, horizon
            )

        # --- Step 3: Optimization Loop ---
        for i in range(max_iterations):
            ctx.iteration = i + 1
            logger.info(f"=== Iteration {ctx.iteration}/{max_iterations} ===")
            
            # 3a. Planning
            if "planner" in self.agents:
                logger.info("ğŸ¤– Planner Agent deciding strategy...")
                plan = self.agents["planner"].create_plan(
                    context=ctx,
                    analysis=ctx.analysis_report,
                    feedback=ctx.last_critique
                )
            else:
                plan = self._fallback_planning(ctx)
            
            ctx.current_plan = plan
            
            # 3b. Execution
            logger.info("ğŸš€ Executing experiment...")
            try:
                # ForecasterAgent (wrapper) ãŒã‚ã‚‹å ´åˆã¯ãã¡ã‚‰ã‚’ä½¿ã†
                if "forecaster" in self.agents and hasattr(self.agents["forecaster"], "run_single"):
                    # ForecasterAgent ã‚’ä½¿ã†å ´åˆã®ãƒ‘ã‚¹ (EasyTSFçµŒç”±ãªã©)
                    # ExperimentRecipe ã¸ã®å¤‰æ›ãŒå¿…è¦ã ãŒã€ã“ã“ã§ã¯ç°¡æ˜“çš„ã« run_loto_experiment ã‚’å‘¼ã¶
                    # å®Ÿéš›ã¯ ForecasterAgent å†…éƒ¨ã§ run_loto_experiment ã‚’å‘¼ã‚“ã§ã„ã‚‹
                    # ã“ã“ã§ã¯æ—¢å­˜ã®ç›´æ¥å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ã™ã‚‹
                    pass

                preds, meta = run_loto_experiment(
                    table_name=table_name,
                    loto=loto,
                    unique_ids=unique_ids,
                    horizon=horizon,
                    agent_metadata={
                        "session_id": session_id,
                        "iteration": ctx.iteration,
                        "analyst_report": ctx.analysis_report,
                        "planner_rationale": plan.get("rationale", "")
                    },
                    model_name=plan.get("model_name", "AutoNHITS"),
                    backend=plan.get("backend", "optuna"),
                    num_samples=plan.get("num_samples", 10),
                    use_rag=(ctx.rag_patterns is not None),
                    **plan.get("model_params", {})
                )
                
                result = ExperimentResult(preds=preds, meta=meta)
                results.append(result)
                
                # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢æ›´æ–°ãƒã‚§ãƒƒã‚¯
                current_score = self._get_metric(meta, goal_metric)
                if current_score < ctx.best_score:
                    ctx.best_score = current_score
                    ctx.best_run_id = meta.get("run_id")

            except Exception as e:
                logger.error(f"Execution failed: {e}")
                ctx.last_critique = f"Execution failed: {str(e)}"
                continue

            # 3c. Reflection
            if "reflection" in self.agents:
                logger.info("ğŸ¤– Reflection Agent evaluating...")
                critique, is_satisfied = self.agents["reflection"].evaluate(
                    result=result,
                    goal_metric=goal_metric,
                    history=ctx.history
                )
                ctx.last_critique = critique
                
                if is_satisfied:
                    logger.info("âœ… Reflection Agent is satisfied. Stopping loop.")
                    break
            else:
                ctx.last_critique = f"Score was {current_score}. Try to improve."

        return results

    def run_full_cycle(
        self,
        task: TimeSeriesTaskSpec,
        table_name: str,
        loto: str,
        unique_ids: List[str]
    ) -> Tuple[ExperimentOutcome, AgentReport]:
        """
        TSResearchOrchestrator äº’æ›ã®ãŸã‚ã®ãƒ©ãƒƒãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰.
        run_autonomous_loop ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ãƒ¬ã‚¬ã‚·ãƒ¼/ãƒ‰ãƒ¡ã‚¤ãƒ³å½¢å¼ã«å¤‰æ›ã—ã¦è¿”ã™ã€‚
        """
        logger.info("Running full cycle via compatibility layer...")
        
        # 1. å®Ÿè¡Œ
        results = self.run_autonomous_loop(
            table_name=table_name,
            loto=loto,
            unique_ids=list(unique_ids),
            horizon=task.target_horizon,
            goal_metric=task.objective_metric,
            max_iterations=3 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        )
        
        # 2. çµæœã®å¤‰æ›
        if not results:
            logger.warning("No results from autonomous loop.")
            return ExperimentOutcome(
                best_model_name="none",
                metrics={},
                all_model_metrics={},
                run_ids=[],
                meta={"status": "no_results"}
            ), AgentReport(summary="No execution performed.", conclusion="Failed", next_steps=[])
            
        # ãƒ™ã‚¹ãƒˆãƒ©ãƒ³ã®é¸å®š (run_autonomous_loop å†…ã§è¨ˆç®—æ¸ˆã¿ã®ãƒ™ã‚¹ãƒˆã‚’ä½¿ã†ã‹ã€ã“ã“ã§ã‚‚ã†ä¸€åº¦æ¢ã™)
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«æœ€å¾Œã®çµæœã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹ã‹ã€æœ¬æ¥ã¯ãƒ™ã‚¹ãƒˆã‚’æ¢ã™ã¹ã
        best_res = results[-1] # ä»®
        best_meta = best_res.meta
        
        outcome = ExperimentOutcome(
            best_model_name=best_meta.get("model_name", "unknown"),
            metrics=best_meta.get("metrics", {}),
            all_model_metrics={r.meta.get("model_name", f"run_{i}"): r.meta.get("metrics", {}) for i, r in enumerate(results)},
            run_ids=[str(r.meta.get("run_id")) for r in results],
            meta=best_meta
        )
        
        report = AgentReport(
            summary=f"Executed {len(results)} iterations.",
            conclusion="Completed successfully.",
            next_steps=["Analyze detailed metrics in DB."]
        )
        
        return outcome, report

    def _fallback_planning(self, ctx: OrchestratorContext) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸åœ¨æ™‚ã®ç°¡æ˜“ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°."""
        models = ["AutoNHITS", "AutoTFT", "Time-MoE-50M"]
        idx = (ctx.iteration - 1) % len(models)
        return {
            "model_name": models[idx],
            "backend": "optuna",
            "num_samples": 5,
            "rationale": "Fallback selection"
        }

    def _get_metric(self, meta: Dict[str, Any], metric_name: str) -> float:
        metrics = meta.get("metrics", {})
        return float(metrics.get(metric_name, float("inf")))
    
    def load_sample(self, table_name: str, loto: str, unique_ids: Sequence[str]) -> pd.DataFrame:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ (TSResearchOrchestratorã‹ã‚‰å‘¼ã°ã‚Œã‚‹)."""
        # å®Ÿéš›ã«ã¯ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
        try:
            from nf_loto_platform.db import loto_repository
            return loto_repository.load_panel_data(table_name, loto, list(unique_ids))
        except Exception:
            return pd.DataFrame()


@dataclass
class EasyTSFConfig:
    """EasyTSF äº’æ›ã®è¨­å®šã‚¯ãƒ©ã‚¹."""
    raw: Dict[str, Any]

    @classmethod
    def from_file(cls, path: Union[str, Path]) -> EasyTSFConfig:
        import json
        with open(path, "r", encoding="utf-8") as f:
            return cls(raw=json.load(f))

    @property
    def dataset(self) -> Dict[str, Any]:
        return self.raw.get("dataset", {})

    @property
    def experiment(self) -> Dict[str, Any]:
        return self.raw.get("experiment", {})

    @property
    def strategy(self) -> Dict[str, Any]:
        return self.raw.get("strategy", {})


def run_easytsf(
    cfg: EasyTSFConfig, 
    tag: Optional[str] = None
) -> Tuple[ExperimentOutcome, AgentReport, Dict[str, Any]]:
    """EasyTSF ã‚¹ã‚¿ã‚¤ãƒ«ã®å®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ."""
    
    # è¨­å®šã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡º
    table_name = cfg.dataset.get("table", "nf_loto_panel")
    loto = cfg.dataset.get("loto", "loto6")
    unique_ids = cfg.dataset.get("unique_ids", [])
    if not unique_ids:
        raise ValueError("unique_ids must be specified in dataset config")
        
    horizon = cfg.experiment.get("horizon", 28)
    objective = cfg.experiment.get("objective", "mae")
    
    # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®æ§‹ç¯‰
    # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹æˆã‚’ä½¿ç”¨
    base_orch = AgentOrchestrator()
    
    if TSResearchOrchestrator is None:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ã‚°æ©Ÿèƒ½ãªã—ã§å®Ÿè¡Œ
        logger.warning("TSResearchOrchestrator not found. Running without research logging.")
        task = TimeSeriesTaskSpec(
            loto_kind=loto,
            target_horizon=horizon,
            objective_metric=objective
        )
        outcome, report = base_orch.run_full_cycle(
            task=task,
            table_name=table_name,
            loto=loto,
            unique_ids=unique_ids
        )
        meta = {"status": "no_logging"}
    else:
        # TSResearchOrchestrator ã§ãƒ©ãƒƒãƒ— (ãƒ­ã‚°è¨˜éŒ²ã®ãŸã‚)
        ts_orch = TSResearchOrchestrator(base_orchestrator=base_orch)
        
        task = TimeSeriesTaskSpec(
            loto_kind=loto,
            target_horizon=horizon,
            objective_metric=objective
        )
        
        outcome, report, meta = ts_orch.run_full_cycle_with_logging(
            task=task,
            table_name=table_name,
            loto=loto,
            unique_ids=unique_ids
        )
    
    if tag:
        meta["tag"] = tag
        
    return outcome, report, meta