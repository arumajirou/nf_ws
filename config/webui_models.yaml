# config/webui_models.yaml

# ============================================================================
# Global Backend Settings
# ============================================================================
default_backends:
  optuna:
    num_samples: 50
    use_pruning: true
    timeout_hours: 4.0  # タイムアウトを明示的に設定
    n_startup_trials: 10
    n_warmup_steps: 50

  ray:
    num_samples: 50
    use_pruning: true
    timeout_hours: 4.0
    max_concurrent_trials: 4
    
  # [New] TSFM Backend (Zero-shot / Inference only)
  tsfm:
    mode: "zero_shot"   # zero_shot | fine_tune
    device: "cuda"      # cuda | cpu
    compile: true       # torch.compile() の使用 (Time-MoE等で有効)

# ============================================================================
# Resource Management
# ============================================================================
resource_limits:
  max_concurrent_runs: 5
  default_cpus: 4
  default_gpus: 1.0     # TSFMはGPUメモリを多く消費するため明示
  gpu_memory_buffer_mb: 2048 # TSFMロード用に確保するバッファ

# ============================================================================
# Optimization Presets (NeuralForecast)
# ============================================================================
model_presets:
  quick:
    description: "迅速な動作確認用"
    num_samples: 10
    max_steps: 500
    batch_size: 64
    early_stop_patience_steps: 3

  balanced:
    description: "精度と時間のバランス重視"
    num_samples: 50
    max_steps: 1000
    batch_size: 128
    early_stop_patience_steps: 5

  accurate:
    description: "最高精度を目指す長時間学習"
    num_samples: 100
    max_steps: 3000
    batch_size: 256
    early_stop_patience_steps: 10
    
  # [New] Foundation Model Presets
  zero_shot_fast:
    description: "基盤モデルによる高速推論 (Zero-shot)"
    backend: "tsfm"
    num_samples: 1     # 探索なし
    context_length: 512
    
  zero_shot_accurate:
    description: "長いコンテキストを用いた高精度推論 (Zero-shot)"
    backend: "tsfm"
    num_samples: 1
    context_length: 2048
    num_beams: 3       # ビームサーチ（生成モデル用）

# ============================================================================
# Supported Models List
# ============================================================================
supported_models:
  # --- NeuralForecast Core Models ---
  - NHITS
  - NBEATS
  - TFT
  - MLP
  - DLinear
  - TSMixer
  - PatchTST
  - Transformer
  - DeepAR
  - DeepNPTS
  - NBEATSx
  - BiTCN
  - TiDE
  - TimesNet
  - TimeLLM
  - StemGNN
  - HINT
  - LSTM
  - GRU
  - RNN
  - TCN
  - VanillaTransformer
  - Informer
  - Autoformer
  - FEDformer
  - iTransformer
  - SOFTS
  - MLPMultivariate
  - TSMixerMultivariate
  
  # --- [New] Time Series Foundation Models (TSFM) ---
  - Time-MoE-50M       # 軽量版 Mixture of Experts
  - Time-MoE-2.4B      # 大規模版 (要GPU 24GB+)
  - MOMENT-Large       # Multi-domain Pre-trained
  - Chronos-Small      # T5ベース (CPUでも動作可)
  - Chronos-Large      # T5ベース (高精度)
  - TimeGPT-1          # Nixtla API
  - TempoPFN           # Tabular Foundation Model for Time Series

# ============================================================================
# Model Specific Default Hyperparameters (Optional Overrides)
# ============================================================================
model_defaults:
  Time-MoE-2.4B:
    context_length: 2048
    patch_len: 16
    stride: 8
    
  Chronos-Large:
    context_length: 512
    prediction_length: 64
    num_samples: 20    # 確率的生成のサンプリング数